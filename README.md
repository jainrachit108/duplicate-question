# NLP Project: Quora Duplicate Question Pair

This repository contains the code and resources for the NLP project on detecting duplicate question pairs in Quora. The project is deployed on Streamlit and can be accessed at [https://duplicate-question.streamlit.app/](https://duplicate-question.streamlit.app/).

## Project Overview
The goal of this project is to identify duplicate question pairs on Quora using natural language processing techniques. The project involves various stages such as data preprocessing, feature engineering, exploratory data analysis (EDA), model training, and deployment.

## Repository Structure
The repository has the following structure:

- `notebooks`: This directory contains Jupyter notebooks related to the project. The main notebook is `Quora_Duplicate_Question_Pair.ipynb`, which includes the step-by-step implementation and analysis of the project.

- `src`: This directory contains Python scripts used in the project.
  - `app.py`: The main script for running the Streamlit application.
  - `decompress.py`: A script to decompress the `model.pkl.gz` file.
  - `model_training.py`: A script containing important functions for preprocessing, feature creation, and model training.
  - `setup.py`: A setup script to install the required dependencies specified in `requirements.txt`.

- `data`: This directory contains the dataset used for training and evaluation. The original dataset is stored in `quora_questions.csv`, and the preprocessed dataset is stored in `preprocessed_questions.csv`.

- `models`: This directory is used for storing trained machine learning models. The compressed model file `model.pkl.gz` is stored here.

## Data Preprocessing
The dataset underwent preprocessing steps to clean the text. This included removing URLs, usernames, HTML tags, and replacing contractions. Punctuation marks were also removed from the text to prepare it for further analysis.

## Feature Engineering
A set of 18 new features were created for the dataset. These features included common words, word share, token features, and fuzzy features. These additional features provided valuable insights and improved the model's performance.

## Exploratory Data Analysis (EDA)
EDA was performed on the dataset to gain a better understanding of the data distribution, identify patterns, and explore relationships between variables. Various visualizations and statistical analysis techniques were employed to extract meaningful insights.

## Model Training
Several machine learning models were trained on the dataset, including Random Forest, Logistic Regression, and Support Vector Classifier (SVC). Random Forest achieved the highest accuracy among the models, so hyperparameter tuning was performed to optimize its performance. The final tuned Random Forest model achieved an accuracy of around 81 percent.

## Deployment
The project was deployed using Streamlit, a Python library for creating web applications. The `app.py` script in the `src` directory contains the code for running the Streamlit application. The deployed application allows users to input question pairs and predict whether they are duplicates or not.

## Additional Files
- `decompress.py`: This script can be used to decompress the `model.pkl.gz` file into the `model.pkl` file for usage.
- `model_training.py`: This script contains important functions for data preprocessing, feature creation, and model training. It provides a modular approach to the project implementation.
- `setup.py`: This script enables the installation of the required dependencies specified in `requirements.txt` by running `python setup.py install`.

## Getting Started
To run the Streamlit application locally, follow these steps:
1. Clone the repository:
   ```bash
   git clone https://github.com/jainrachit108/duplicate-question.git
   ```
2. Install the required dependencies:
   ```bash
   pip install -r requirements.txt
   ```
3. Navigate to the `src` directory:


   ```bash
   cd src
   ```
4. Run the Streamlit application:
   ```bash
   streamlit run app.py
   ```

## Contact
For any questions or inquiries, please contact jainrachit124@gmail.com.

Feel free to explore the code, experiment with different models, and enhance the project further. Your contributions are welcome!

**Note:** The trained model file `model.pkl` is not included in this repository due to its large size. However, it can be generated by following the instructions in the `decompress.py` script.
